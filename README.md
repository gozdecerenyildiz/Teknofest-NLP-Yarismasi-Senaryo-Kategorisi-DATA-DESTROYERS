# Teknofest2024 TÃ¼rkÃ§e DoÄŸal Dil Ä°ÅŸleme YarÄ±ÅŸmasÄ±   -Senaryo Kategorisi-  TakÄ±m: DATA DESTROYERS
**TakÄ±m AdÄ±:** DATA DESTROYERS  
**BaÅŸvuru Id:** 2290170  
![image](https://github.com/user-attachments/assets/4505e9fa-d976-4fc8-8405-8e172ee0211d)

## Ekibimiz
![image](https://github.com/user-attachments/assets/6f053871-50cf-468c-bce0-4f456586f187)

## ğŸ“œ Projenin TanÄ±mÄ±
Bu FastAPI projesi, Teknofest2024 TÃ¼rkÃ§e DoÄŸal Dil Ä°ÅŸleme YarÄ±ÅŸmasÄ± Senaryo Kategorisi iÃ§in Data Destroyers Ekibi tarafÄ±ndan, Turkcell final senaryosu kapsamÄ±nda; belirli bir metin girdisine dayalÄ± olarak varlÄ±k (entity) tanÄ±ma ve duygu (sentiment) analizi yapan bir API hizmeti sunmak amacÄ±yla yapÄ±lmÄ±ÅŸtÄ±r. YapmÄ±ÅŸ olduÄŸumuz bu proje, kullanÄ±cÄ±dan bir metin alÄ±r, bu metin Ã¼zerinde analiz yapar ve belirli varlÄ±klarÄ± tanÄ±yarak her bir varlÄ±k iÃ§in duygu analizini gerÃ§ekleÅŸtirir.
Ã–zellikle sosyal medya, mÃ¼ÅŸteri geri bildirimleri veya herhangi bir metin tabanlÄ± veri kaynaÄŸÄ±ndaki varlÄ±klarÄ±n (ÅŸirket isimleri, Ã¼rÃ¼nler, hizmetler vb.) tespit edilmesi ve bu varlÄ±klarla ilgili olumlu, olumsuz veya nÃ¶tr duygularÄ±n sÄ±nÄ±flandÄ±rÄ±lmasÄ± hedeflenmektedir.

## ğŸ¯ Projenin AmacÄ±
- **VarlÄ±k TanÄ±ma (Entity Recognition):** Metin iÃ§erisindeki belirli kiÅŸi, yer, organizasyon vb. varlÄ±klarÄ± tanÄ±mlamak.
- **Duygu Analizi (Sentiment Analysis):** TanÄ±mlanan her bir varlÄ±k iÃ§in metindeki duygusal tonu (olumlu, olumsuz, nÃ¶tr) belirlemek.

## ğŸš€ Projemizin SaÄŸladÄ±ÄŸÄ± Ã‡Ã¶zÃ¼mler
- KullanÄ±cÄ±larÄ±n metinlerinde yer alan varlÄ±klarÄ±n (entitelerin) doÄŸru bir ÅŸekilde tanÄ±nmasÄ±.TanÄ±nan her varlÄ±k iÃ§in duygu analizi yapÄ±larak, varlÄ±ÄŸÄ±n taÅŸÄ±dÄ±ÄŸÄ± duygunun belirlenmesi (olumlu, olumsuz, nÃ¶tr).

- Proje FastAPI framework'Ã¼ kullanÄ±larak bir API olarak sunulmaktadÄ±r. Bu API'ye gÃ¶nderilen metinler Ã¼zerinde varlÄ±k tanÄ±ma ve duygu analizi gerÃ§ekleÅŸtirilir ve sonuÃ§lar JSON formatÄ±nda dÃ¶ndÃ¼rÃ¼lÃ¼r.

- Bu proje, varlÄ±k tanÄ±ma (NER) ve duygu analizi (sentiment analysis) iÃ§in bir FastAPI uygulamasÄ± sunar. KullanÄ±cÄ±lar API'ye bir metin gÃ¶nderir ve sistem, metin iÃ§erisinde yer alan varlÄ±klarÄ± tespit eder ve bu varlÄ±klarÄ±n duygu durumunu belirler. 

- AyrÄ±ca, bu tÃ¼r projeler, TÃ¼rkÃ§e dilinde veri analizi yapma kapasitesini artÄ±rarak, TÃ¼rkÃ§e'nin dijital dÃ¼nya Ã¼zerindeki kullanÄ±mÄ±nÄ± ve dil teknolojileri alanÄ±ndaki temsilini gÃ¼Ã§lendirmektedir.
- 
## ğŸ“‚ Dosyalar

- `main.py`: UygulamanÄ±n ana dosyasÄ±.
- `requirements.txt`: Projede kullanÄ±lan Python baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ±n listesi.
-`sentiment_data.7z` : Projede kullanÄ±lan datanÄ±n son hali
-`analiz.ipynb` : Proje modelleme aÅŸamalarÄ±nÄ±n bulunduÄŸu jupyternotebook dosyasÄ±


## ğŸ“ˆ Proje AÅŸamalarÄ±
Proje 4 ana aÅŸamadan oluÅŸmaktadÄ±r:

### A) Web-Scraping ile Negatif Veri Toplama AÅŸamalarÄ±
- **Web-scraping kullanÄ±larak sikayetvar.com sitesindeki Turkcell'e ait TÃ¼rkÃ§e ÅŸikayet yorumlarÄ± (negatif sentiment verileri) nlp de kullanÄ±lmak Ã¼zere kategorilerine gÃ¶re (cayma, superbox vb.) otomatik olarak toplanÄ±p analiz edilebilir hale getirildi.**

#### Web Scraping KullanÄ±lan KÃ¼tÃ¼phaneler ve AmaÃ§larÄ±
1. **Selenium (webdriver, By, WebDriverWait, EC, ActionChains):**
   - `webdriver`: Web tarayÄ±cÄ±sÄ±nÄ± otomatikleÅŸtirmek iÃ§in kullanÄ±ldÄ±.
   - `By`: Web sayfasÄ±ndaki Ã¶ÄŸeleri bulmak iÃ§in Ã§eÅŸitli yÃ¶ntemler saÄŸladÄ±ÄŸÄ± iÃ§in kullanÄ±ldÄ±.
   - `WebDriverWait`, `EC`: TanÄ±mlanmÄ±ÅŸ belirli koÅŸullarÄ±n oluÅŸmasÄ±nÄ± beklemek iÃ§in kullanÄ±ldÄ±.
   - `ActionChains`: Web sayfasÄ±nda Ã§eÅŸitli etkileÅŸimler (Ã–rneÄŸin; fare hareketleri, tÄ±klamalar) gerÃ§ekleÅŸtirmek iÃ§in kullanÄ±ldÄ±.
2. **BeautifulSoup (BeautifulSoup):** 
   - Web sayfasÄ±nÄ±n HTML iÃ§eriÄŸini ayrÄ±ÅŸtÄ±rmak ve belirli Ã¶ÄŸeleri bulmak iÃ§in kullanÄ±ldÄ±.
3. **Urllib (urljoin):**
   - GÃ¶receli URL'leri tam URL'lere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±ldÄ±.

#### Kodun Ä°ÅŸleyiÅŸi
1. **BaÅŸlatma ve URL'leri Ziyaret Etme:**
   - WebDriver baÅŸlatÄ±lÄ±r ve sikayetvar.com sitesindeki Turkcellin kategorilerine ait  ÅŸikayet sayfalarÄ± ayrÄ± ayrÄ± ziyaret edilir.
2. **Veri Toplama:**
   - Her ayrÄ± kategori ve sayfada bulunan ÅŸikayetlerin detay sayfalarÄ±na gidilir ve ÅŸikayetlerin baÅŸlÄ±klarÄ± ve iÃ§erikleri toplanÄ±r.
3. **Verileri DÃ¼zenleme ve Kaydetme:**
   - Toplanan veriler pandas DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve bir CSV dosyasÄ±na kaydedilir.

### B) HuggingFace ile Veri Toplama
- **Sentiment sÃ¼tununa sahip TÃ¼rkÃ§e yorum verilerinin (https://huggingface.co/datasets/asparius/Turkish-Product-Review) (https://huggingface.co/datasets/winvoker/turkish-sentiment-analysis-dataset) elde edilmesi:**

#### ğŸ“¥ Veri Setini Ä°ndirme
1.  Hugging Face Datasets kÃ¼tÃ¼phanesini kullanarak "asparius/Turkish-Product-Review" ve "turkish-sentiment-analysis-dataset" veri setinin eÄŸitim bÃ¶lÃ¼mÃ¼ ÅŸu kod ile indirilir:

train_dataset = dataset['train']

![image](https://github.com/user-attachments/assets/ce50092d-e606-456d-917c-4d168ef64c47)


### C) Verilerin Ã–n Temizleme Ä°ÅŸlem AdÄ±mlarÄ±
- **Web scraping ve Hugging Face Datasets ile elde edilen tÃ¼m verilerin Ã¶n temizleme iÅŸlemleri:**

- SayÄ±larÄ± kaldÄ±rma,
- Fazla boÅŸluklarÄ± kaldÄ±rma,
- TÃ¼rkÃ§e durdurma iÅŸaretlerini (stopwords-tr.txt) kaldÄ±rma,
- Noktalama iÅŸaretlerini kaldÄ±rma,
- Ã–zel karakterleri kaldÄ±rma vb. iÅŸlem adÄ±mlarÄ± ile yapÄ±lÄ±r.

![WhatsApp Image 2024-08-09 at 10 03 47](https://github.com/user-attachments/assets/8f7bc47e-6e57-4cf0-b7ae-129757b54fdc)

![WhatsApp Image 2024-08-09 at 10 03 53](https://github.com/user-attachments/assets/c41a927f-c8e6-42f5-89b1-cef4183d0902)

![WhatsApp Image 2024-08-09 at 10 03 57](https://github.com/user-attachments/assets/5958de1e-0ba5-446f-83e0-29a9fd3deec3)

  
### D) DoÄŸal Dil Ä°ÅŸleme SÃ¼reci AdÄ±mlarÄ± 
#### 1. KullanÄ±lan KÃ¼tÃ¼phaneler
- **pandas:** CSV dosyasÄ±nÄ± okumak ve veri iÅŸlemek iÃ§in kullanÄ±lÄ±r.
- **matplotlib:** Grafik Ã§izimleri yapmak iÃ§in kullanÄ±lÄ±r.
- **sklearn:** Performans metriklerini hesaplamak iÃ§in kullanÄ±lÄ±r.
- **wordcloud:** Metin verilerini gÃ¶rselleÅŸtirmek iÃ§in kullanÄ±lÄ±r. Kelime bulutu (word cloud) oluÅŸturma amaÃ§lÄ±dÄ±r.
- **sklearn.model_selection.train_test_split:** Verileri eÄŸitim ve test setlerine ayÄ±rmak iÃ§in kullanÄ±lÄ±r. Model doÄŸruluÄŸunu deÄŸerlendirmek iÃ§in gereklidir.
- **sklearn.feature_extraction.text.CountVectorizer:** Metin verilerini sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lÄ±r. Bu dÃ¶nÃ¼ÅŸÃ¼m, tokenization ve sayma iÅŸlemiyle yapÄ±lÄ±r.
- **sklearn.linear_model.LogisticRegression:** Lojistik regresyon modeli oluÅŸturmak iÃ§in kullanÄ±lÄ±r. Bu model, sÄ±nÄ±flandÄ±rma problemleri iÃ§in yaygÄ±n olarak kullanÄ±lÄ±r.
- **sklearn.metrics:** Model performansÄ±nÄ± deÄŸerlendirmek iÃ§in Ã§eÅŸitli metrikler saÄŸlar, Ã¶rneÄŸin doÄŸruluk, hassasiyet, kesinlik, F1 skoru gibi.
- **seaborn:** Veri gÃ¶rselleÅŸtirme iÃ§in kullanÄ±lÄ±r ve Ã¶zellikle istatistiksel grafikler oluÅŸturmak iÃ§in uygundur.
- **sklearn.naive_bayes:** Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ± modelleri oluÅŸturmak iÃ§in kullanÄ±lÄ±r.
- **sklearn.feature_extraction.text.TfidfVectorizer:** Metin verilerini sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lÄ±r. Term Frequency-Inverse Document Frequency (TF-IDF) yÃ¶ntemini kullanÄ±r.
- **joblib:** Modeli seri hale getirmek (serialize) ve kaydetmek iÃ§in kullanÄ±lÄ±r. EÄŸitilen modellerin yeniden kullanÄ±labilir hale getirilmesini saÄŸlar.
  
#### 2. Veriyi Okuma
- Pandas kÃ¼tÃ¼phanesi, Ã¶n temizleme yapÄ±lmÄ±ÅŸ verilerin CSV dosyasÄ±ndan yÃ¼klenmesi iÃ§in kullanÄ±ldÄ±.

#### 3. Metin ve Etiketlerin HazÄ±rlanmasÄ±
- Modelin anlayabileceÄŸi bir formatta metin verileri ve etiketler hazÄ±rlandÄ±. astype(str) ve astype(int) ile tip dÃ¶nÃ¼ÅŸÃ¼mleri yapÄ±larak veriler listelere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.

#### 4. VektÃ¶rizasyon Teknikleri
- Bu projede vektÃ¶rizasyon iÅŸlemi CountVectorizer ve TfidfVectorizer kullanÄ±larak gerÃ§ekleÅŸtirilmiÅŸtir:

**CountVectorizer:** Metin iÃ§erisindeki her kelimeyi bir token olarak alÄ±r ve bu kelimelerin dokÃ¼mandaki sayÄ±sÄ±nÄ± hesaplar. Bu yÃ¶ntem, metni kelime sayÄ±larÄ±yla temsil eden bir matrise dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
- 1-Gram: Her bir kelime iÃ§in vektÃ¶rler oluÅŸturulmuÅŸtur.
- 2-Gram: 1 ve 2 kelimelik kombinasyonlar iÃ§in vektÃ¶rler oluÅŸturulmuÅŸtur (N-Gram yÃ¶ntemi).
**TfidfVectorizer:*** CountVectorizer'a benzer ÅŸekilde metni kelime tokenlerine ayÄ±rÄ±r, ancak bu kelimelerin Ã¶nemini de dikkate alÄ±r. TF-IDF skoru, bir kelimenin bir dokÃ¼mandaki Ã¶nemini hesaplamak iÃ§in kullanÄ±lÄ±r. Daha sÄ±k geÃ§en ancak Ã§ok yaygÄ±n olmayan kelimelere daha yÃ¼ksek aÄŸÄ±rlÄ±k verilir.
- 1-Gram TF-IDF: Tek kelimelik tokenlar iÃ§in TF-IDF vektÃ¶rleri oluÅŸturulmuÅŸtur.
- 2-Gram TF-IDF: 1 ve 2 kelimelik kombinasyonlar iÃ§in TF-IDF vektÃ¶rleri oluÅŸturulmuÅŸtur.
Bu iki teknik, metin verilerinin makine Ã¶ÄŸrenimi modelleri iÃ§in uygun hale getirilmesini saÄŸlar. Tokenization, kelime Ã¶beklerini **(n-grams)** de hesaba katarak, daha anlamlÄ± bir metin temsili oluÅŸturulur.

#### 5.Model Kurulumu ve EÄŸitimi
**Logistic Regression:**
* LogisticRegression modeli kullanÄ±larak sÄ±nÄ±flandÄ±rma modeli oluÅŸturulmuÅŸ ve eÄŸitim verileri ile eÄŸitilmiÅŸtir.
* Hem kelime bazlÄ± vektÃ¶rlerle (CountVectorizer kullanarak) hem de N-Gram vektÃ¶rleriyle (N-Gram CountVectorizer) modeller eÄŸitilmiÅŸtir.
* AyrÄ±ca, TF-IDF vektÃ¶rleri ile Logistic Regression modelleri de oluÅŸturulmuÅŸtur.
**Naive Bayes:**
* MultinomialNB ve BernoulliNB algoritmalarÄ± kullanÄ±larak Naive Bayes modelleri eÄŸitilmiÅŸtir.
* Bu modeller, hem kelime vektÃ¶rleri hem de N-Gram vektÃ¶rleri ile eÄŸitilmiÅŸ ve test edilmiÅŸtir.
#### 6.Model Performans DeÄŸerlendirmesi
* KarÄ±ÅŸÄ±klÄ±k Matrisi (Confusion Matrix):
* Modellerin performansÄ±, karÄ±ÅŸÄ±klÄ±k matrisi kullanÄ±larak deÄŸerlendirilmiÅŸtir. Bu matriste, modelin tahmin ettiÄŸi ve gerÃ§ek sÄ±nÄ±flar karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r.
* Metrikler: DoÄŸruluk, hassasiyet, kesinlik, F1 skoru gibi metrikler hesaplanmÄ±ÅŸ ve sonuÃ§lar gÃ¶rselleÅŸtirilmiÅŸtir.
#### 7.Modelin Kaydedilmesi
* EÄŸitilen modeller, ileride kullanÄ±lmak Ã¼zere joblib kÃ¼tÃ¼phanesi ile kaydedilmiÅŸtir. AyrÄ±ca, vektÃ¶rizasyon iÅŸlemleri iÃ§in kullanÄ±lan CountVectorizer da kaydedilmiÅŸtir.
* Model ve vektÃ¶rizer birlikte kaydedilerek, tahmin iÅŸlemleri iÃ§in tekrar kullanÄ±labilir hale getirilmiÅŸtir.
* Bu adÄ±mlar, metin verileri Ã¼zerinde gerÃ§ekleÅŸtirilen sÄ±nÄ±flandÄ±rma iÅŸleminin tam iÅŸ akÄ±ÅŸÄ±nÄ± ve kullanÄ±lan yÃ¶ntemleri kapsamaktadÄ±r.

#### 8.Performans Metriklerinin HesaplanmasÄ±
- Kurulan Derin Ã–ÄŸrenme Modelinin performansÄ±nÄ±n deÄŸerlendirilmesi iÃ§in Sklearn Metrikleri(DoÄŸruluk, precision, recall, F1-score, Confisuon Matrix ve ROC AUC) hesaplandÄ±.
  
#### 9.Performans Metriklerinin GrafiÄŸinin Ã‡izdirilmesi
- EÄŸitim ve validasyon kayÄ±plarÄ± ile doÄŸruluklarÄ±nÄ± gÃ¶rselleÅŸtirmek, modelin performansÄ±nÄ± ve Ã¶ÄŸrenme sÃ¼recini anlamamÄ±za yardÄ±mcÄ± olacaÄŸÄ± iÃ§in daha sonra sunum dosyasÄ±nda kullanmak ve deÄŸerlendirmek Ã¼zere kaydedildi.

![image](https://github.com/user-attachments/assets/be0e968b-0b1a-40dc-bcc5-cacbc3843510)

### E) ğŸ–¥ FastAPI (main.py) Ä°ÅŸleyiÅŸi
#### ğŸ“œ 1. Metin Girdisi Alma
- KullanÄ±cÄ±, bir metin girdisi gÃ¶nderir. Bu metin, iÃ§inde Ã§eÅŸitli varlÄ±klar (Ã¶rneÄŸin, ÅŸirket isimleri, platformlar) iÃ§erebilir.

#### ğŸ’¬ 2. VarlÄ±k TanÄ±ma ve Duygu Analizi
- GÃ¶nderilen metin Ã¼zerinde model Ã§alÄ±ÅŸtÄ±rÄ±larak varlÄ±klar tanÄ±mlanÄ±r ve her bir varlÄ±k iÃ§in duygu analizi yapÄ±lÄ±r.

#### ğŸ“ˆ 3.SonuÃ§larÄ± DÃ¶ndÃ¼rme
- TanÄ±mlanan varlÄ±klar ve bunlara iliÅŸkin duygu analizi sonuÃ§larÄ± (pozitif, negatif, nÃ¶tr) kullanÄ±cÄ±ya JSON formatÄ±nda geri dÃ¶ndÃ¼rÃ¼lÃ¼r.

### F) ğŸ“Š SONUÃ‡LAR-ARAYÃœZ
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2024-08-09 092035](https://github.com/user-attachments/assets/6dc06251-728c-452d-a23b-afe52312988f)
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2024-08-09 092041](https://github.com/user-attachments/assets/8ca8d80b-3dab-479d-80ca-d124859b75f3)
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2024-08-09 092111](https://github.com/user-attachments/assets/f025e7f2-ffd9-4ca6-938a-0c50e142c67e)
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2024-08-09 092623](https://github.com/user-attachments/assets/e2c4f594-51e9-40d7-a211-a023246ef91a)
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2024-08-09 093512](https://github.com/user-attachments/assets/8f751805-0fe2-4f2a-9208-5536c8a72893)
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2024-08-09 093528](https://github.com/user-attachments/assets/6a7ea041-1ead-47c8-829c-fd996a82a6cb)
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2024-08-09 091910](https://github.com/user-attachments/assets/ea5a2bc7-7ac3-4ed0-af99-10074cadfd8a)
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2024-08-09 091921](https://github.com/user-attachments/assets/02b5a838-f74c-440f-b681-b72c91d1f3e9)
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2024-08-09 091941](https://github.com/user-attachments/assets/2307e3f8-2f22-47f6-8e62-0b95ee3cda66)
![Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ 2024-08-09 091949](https://github.com/user-attachments/assets/dfc7c2cc-b75c-4e4b-bc73-d02de8e5aee1)


### G) ğŸ”§ Kurulum

1. Projeyi klonlayÄ±n:

    ```bash
    git clone https://github.com/sevimonline/Musteri-Hizmetleri-Cozumleri-Turkce-Platformu-DATA-DESTROYERS](https://github.com/gozdecerenyildiz/Teknofest-NLP-Yarismasi-Seneryo-Kategorisi-DATA-DESTROYERS.git
    ```

2. Proje dizinine gidin:

    ```bash
    cd Teknofest-NLP-Yarismasi-Seneryo-Kategorisi-DATA-DESTROYERS
    ```

3. Gerekli paketleri yÃ¼kleyin:

    ```bash
    pip install -r requirements.txt
    ```

4. UygulamayÄ± baÅŸlatÄ±n:

    ```bash
    python -m uvicorn main:app --reload
    ```

5. TarayÄ±cÄ±nÄ±zda `http://localhost:8000` adresine gidin ve uygulamayÄ± kullanmaya baÅŸlayÄ±n.

### ğŸ‘¥ Ä°letiÅŸim

- LinkedIn: [Berke Sevim](https://www.linkedin.com/in/berke-sevim-1565161a2/)
- LinkedIn: [GÃ¶zde Ceren YÄ±ldÄ±z](https://www.linkedin.com/in/gÃ¶zde-ceren-yÄ±ldÄ±z/)
- LinkedIn: [BÃ¼ÅŸra Sulukan](https://www.linkedin.com/in/bÃ¼ÅŸra-sulukan-82299a177/)

### ğŸ“„ Lisans

Bu proje Apache 2.0 LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.





