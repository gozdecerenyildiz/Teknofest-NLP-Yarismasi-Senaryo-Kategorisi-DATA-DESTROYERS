# #Teknofest2024 TÃ¼rkÃ§e DoÄŸal Dil Ä°ÅŸleme YarÄ±ÅŸmasÄ±   -Senaryo Kategorisi-  TakÄ±m: DATA DESTROYERS
**TakÄ±m AdÄ±:** DATA DESTROYERS  
**BaÅŸvuru Id:** 2290170  

## ğŸ“œ Projenin TanÄ±mÄ±
Bu FastAPI projesi, Teknofest2024 TÃ¼rkÃ§e DoÄŸal Dil Ä°ÅŸleme YarÄ±ÅŸmasÄ± Senaryo Kategorisi iÃ§in Data Destroyers Ekibi tarafÄ±ndan, Turkcell final senaryosu kapsamÄ±nda; belirli bir metin girdisine dayalÄ± olarak varlÄ±k (entity) tanÄ±ma ve duygu (sentiment) analizi yapan bir API hizmeti sunmak amacÄ±yla yapÄ±lmÄ±ÅŸtÄ±r. YapmÄ±ÅŸ olduÄŸumuz bu proje, kullanÄ±cÄ±dan bir metin alÄ±r, bu metin Ã¼zerinde analiz yapar ve belirli varlÄ±klarÄ± tanÄ±yarak her bir varlÄ±k iÃ§in duygu analizini gerÃ§ekleÅŸtirir.

## ğŸ¯ Projenin AmacÄ±
- **VarlÄ±k TanÄ±ma (Entity Recognition):** Metin iÃ§erisindeki belirli kiÅŸi, yer, organizasyon vb. varlÄ±klarÄ± tanÄ±mlamak.
- **Duygu Analizi (Sentiment Analysis):** TanÄ±mlanan her bir varlÄ±k iÃ§in metindeki duygusal tonu (olumlu, olumsuz, nÃ¶tr) belirlemek.

## ğŸ“‚ Dosyalar

- `main.py`: UygulamanÄ±n ana dosyasÄ±.
- `requirements.txt`: Projede kullanÄ±lan Python baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ±n listesi.
-
-
-


## ğŸ“ˆ Proje AÅŸamalarÄ±
Proje 4 ana aÅŸamadan oluÅŸmaktadÄ±r:

### A) Web-Scraping ile Negatif Veri Toplama AÅŸamalarÄ±
- **Web-scraping kullanÄ±larak sikayetvar.com sitesindeki Turkcell'e ait TÃ¼rkÃ§e ÅŸikayet yorumlarÄ± (negatif sentiment verileri) nlp de kullanÄ±lmak Ã¼zere kategorilerine gÃ¶re (cayma, superbox vb.) otomatik olarak toplanÄ±p analiz edilebilir hale getirildi.**

#### Web Scraping KullanÄ±lan KÃ¼tÃ¼phaneler ve AmaÃ§larÄ±
1. **Selenium (webdriver, By, WebDriverWait, EC, ActionChains):**
   - `webdriver`: Web tarayÄ±cÄ±sÄ±nÄ± otomatikleÅŸtirmek iÃ§in kullanÄ±ldÄ±.
   - `By`: Web sayfasÄ±ndaki Ã¶ÄŸeleri bulmak iÃ§in Ã§eÅŸitli yÃ¶ntemler saÄŸladÄ±ÄŸÄ± iÃ§in kullanÄ±ldÄ±.
   - `WebDriverWait`, `EC`: TanÄ±mlanmÄ±ÅŸ belirli koÅŸullarÄ±n oluÅŸmasÄ±nÄ± beklemek iÃ§in kullanÄ±ldÄ±.
   - `ActionChains`: Web sayfasÄ±nda Ã§eÅŸitli etkileÅŸimler (Ã–rneÄŸin; fare hareketleri, tÄ±klamalar) gerÃ§ekleÅŸtirmek iÃ§in kullanÄ±ldÄ±.
2. **BeautifulSoup (BeautifulSoup):** 
   - Web sayfasÄ±nÄ±n HTML iÃ§eriÄŸini ayrÄ±ÅŸtÄ±rmak ve belirli Ã¶ÄŸeleri bulmak iÃ§in kullanÄ±ldÄ±.
3. **Urllib (urljoin):**
   - GÃ¶receli URL'leri tam URL'lere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±ldÄ±.

#### Kodun Ä°ÅŸleyiÅŸi
1. **BaÅŸlatma ve URL'leri Ziyaret Etme:**
   - WebDriver baÅŸlatÄ±lÄ±r ve sikayetvar.com sitesindeki Turkcellin kategorilerine ait  ÅŸikayet sayfalarÄ± ayrÄ± ayrÄ± ziyaret edilir.
2. **Veri Toplama:**
   - Her ayrÄ± kategori ve sayfada bulunan ÅŸikayetlerin detay sayfalarÄ±na gidilir ve ÅŸikayetlerin baÅŸlÄ±klarÄ± ve iÃ§erikleri toplanÄ±r.
3. **Verileri DÃ¼zenleme ve Kaydetme:**
   - Toplanan veriler pandas DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve bir CSV dosyasÄ±na kaydedilir.

### B) HuggingFace ile Veri Toplama
- **Sentiment sÃ¼tununa sahip TÃ¼rkÃ§e yorum verilerinin (https://huggingface.co/datasets/asparius/Turkish-Product-Review) (https://huggingface.co/datasets/winvoker/turkish-sentiment-analysis-dataset) elde edilmesi:**

#### Veri Setini Ä°ndirme
1.  Hugging Face Datasets kÃ¼tÃ¼phanesini kullanarak "asparius/Turkish-Product-Review" ve "turkish-sentiment-analysis-dataset" veri setinin eÄŸitim bÃ¶lÃ¼mÃ¼ ÅŸu kod ile indirilir:

train_dataset = dataset['train']

   ------------ VERÄ° SETÄ° HAKKINDA BÄ°LGÄ° GÃ–RSELÄ° BURAYA EKLENECEK ( KAÃ‡ ADET DATA, KAÃ‡I NÃ–TR,KAÃ‡I POZÄ°TÄ°F,KAÃ‡I NEGATÄ°F VB) ------- 

### C) Verilerin Ã–n Temizleme Ä°ÅŸlem AdÄ±mlarÄ±
- **Web scraping ve Hugging Face Datasets ile elde edilen tÃ¼m verilerin Ã¶n temizleme iÅŸlemleri:**

- SayÄ±larÄ± kaldÄ±rma,
- Fazla boÅŸluklarÄ± kaldÄ±rma,
- TÃ¼rkÃ§e durdurma iÅŸaretlerini (stopwords-tr.txt) kaldÄ±rma,
- Noktalama iÅŸaretlerini kaldÄ±rma,
- Ã–zel karakterleri kaldÄ±rma vb. iÅŸlem adÄ±mlarÄ± ile yapÄ±lÄ±r.

  ----------- VERÄ° SETÄ° WORD CLOUD GÃ–RSELÄ° VE NLP GÃ–RSELLERÄ° BURAYA EKLENECEK------------
  
### D) DoÄŸal Dil Ä°ÅŸleme SÃ¼reci AdÄ±mlarÄ± - Derin Ã–ÄŸrenme
#### 1. KullanÄ±lan KÃ¼tÃ¼phaneler
- pandas: CSV dosyasÄ±nÄ± okumak ve veri iÅŸlemek iÃ§in kullanÄ±lÄ±r.
- tensorflow: Model eÄŸitimi ve veri iÅŸleme iÃ§in kullanÄ±lÄ±r.
- matplotlib: Grafik Ã§izimleri yapmak iÃ§in kullanÄ±lÄ±r.
- sklearn: Performans metriklerini hesaplamak iÃ§in kullanÄ±lÄ±r.
- transformers: BERT modelini ve tokenizer'Ä± yÃ¼klemek iÃ§in kullanÄ±lÄ±r.
#### 2. Veriyi Okuma
- Pandas kÃ¼tÃ¼phanesi, Ã¶n temizleme yapÄ±lmÄ±ÅŸ verilerin CSV dosyasÄ±ndan yÃ¼klenmesi iÃ§in kullanÄ±ldÄ±.

#### 3. Metin ve Etiketlerin HazÄ±rlanmasÄ±
- Modelin anlayabileceÄŸi bir formatta metin verileri ve etiketler hazÄ±rlandÄ±. astype(str) ve astype(int) ile tip dÃ¶nÃ¼ÅŸÃ¼mleri yapÄ±larak veriler listelere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.

#### 4. Tokenizasyon
- BertTokenizer, metinlerin belirli bir formatta token'lara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lerek iÅŸlenmesi (metin tokenizasyonu) iÃ§in kullanÄ±ldÄ±. Bu tokenizasyon iÅŸlemi, metinlerin modelin anlayabileceÄŸi input_ids ve attention_mask gibi tensÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesini saÄŸladÄ±. truncation ve padding parametreleri, metinlerin belirli bir uzunlukta olmasÄ±nÄ± ve gerekli dolgularÄ±n yapÄ±lmasÄ±nÄ± saÄŸladÄ±.

#### 5. TensorFlow Veri KÃ¼mesi OluÅŸturma
- Verilerin TensorFlow veri kÃ¼mesi formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi, modelin eÄŸitim sÃ¼recinde verilerin verimli bir ÅŸekilde iÅŸlenmesini saÄŸlar. Verileri eÄŸitim ve validasyon kÃ¼melerine ayÄ±rmak, modelin performansÄ±nÄ± deÄŸerlendirmek iÃ§in Ã¶nemli olduÄŸundan TensorFlow veri kÃ¼mesi oluÅŸturuldu.

#### 6. Ã–ÄŸrenme OranÄ± ZamanlayÄ±cÄ±sÄ± ve Optimizasyon
- PolynomialDecay, Ã¶ÄŸrenme oranÄ±nÄ±n zamanla azalmasÄ±nÄ± saÄŸlayarak modelin eÄŸitim sÃ¼recinde daha stabil hale gelmesine yardÄ±mcÄ± olduÄŸu iÃ§in kullanÄ±ldÄ±. Adam optimizasyon algoritmasÄ± ise gradyan iniÅŸini hÄ±zlandÄ±rarak daha verimli hale getirdiÄŸi iÃ§in derin Ã¶ÄŸrenme modelinde kullanÄ±ldÄ±.

#### 7. EÄŸitim ve Validasyon AdÄ±mlarÄ± Ä°Ã§in Fonksiyonlar
- tf.GradientTape kullanarak gradyanlarÄ± hesaplayan ve optimizer ile modelin aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼ncelleyen, @tf.function dekoratÃ¶rÃ¼ ile TensorFlow grafik modunda Ã§alÄ±ÅŸarak performansÄ± artÄ±ran fonksiyonlar derin Ã¶ÄŸrenme modeli iÅŸlem adÄ±mlarÄ±nda kullanÄ±ldÄ±.

#### 8. EÄŸitim DÃ¶ngÃ¼sÃ¼
- EÄŸitim dÃ¶ngÃ¼sÃ¼, modelin belirli sayÄ±da epoch boyunca eÄŸitim ve validasyon adÄ±mlarÄ±nÄ± tekrarlamasÄ±nÄ± saÄŸlar. Her epoch'ta modelin performansÄ± deÄŸerlendirilir ve kaydedilir. En uygun Epoch bulma algoritmasÄ± kullanÄ±larak derin Ã¶ÄŸrenme modeli iÃ§in Epoch sayÄ±sÄ± 3 olarak belirlendi.

#### 9. Model Kurma
-YukarÄ±da bahsedilen iÅŸlem adÄ±mlarÄ± ile derin Ã¶ÄŸrenme modeli kuruldu.

#### 10. Modeli Kaydetme
- EÄŸitilmiÅŸ modelin ve tokenizer'Ä±n FastAPI arayÃ¼zÃ¼nde kullanmak iÃ§in kaydedildi.

#### 11. Performans Metriklerinin HesaplanmasÄ±
- Kurulan Derin Ã–ÄŸrenme Modelinin performansÄ±nÄ±n deÄŸerlendirilmesi iÃ§in Sklearn Metrikleri(DoÄŸruluk, precision, recall, F1-score, Confisuon Matrix ve ROC AUC) hesaplandÄ±.
  
#### 12. Performans Metriklerinin GrafiÄŸinin Ã‡izdirilmesi
- EÄŸitim ve validasyon kayÄ±plarÄ± ile doÄŸruluklarÄ±nÄ± gÃ¶rselleÅŸtirmek, modelin performansÄ±nÄ± ve Ã¶ÄŸrenme sÃ¼recini anlamamÄ±za yardÄ±mcÄ± olacaÄŸÄ± iÃ§in daha sonra sunum dosyasÄ±nda kullanmak ve deÄŸerlendirmek Ã¼zere kaydedildi.

- ----------- PERFORMANS METRÄ°ÄÄ° VE GRAFÄ°KLERÄ° BURAYA EKLENECEK --------------------------------

### E) ğŸ–¥ FastAPI (main.py) Ä°ÅŸleyiÅŸi
#### 1. Metin Girdisi Alma
- KullanÄ±cÄ±, bir metin girdisi gÃ¶nderir. Bu metin, iÃ§inde Ã§eÅŸitli varlÄ±klar (Ã¶rneÄŸin, ÅŸirket isimleri, platformlar) iÃ§erebilir.

#### 2. VarlÄ±k TanÄ±ma ve Duygu Analizi
- GÃ¶nderilen metin Ã¼zerinde model Ã§alÄ±ÅŸtÄ±rÄ±larak varlÄ±klar tanÄ±mlanÄ±r ve her bir varlÄ±k iÃ§in duygu analizi yapÄ±lÄ±r.

#### 3. SonuÃ§larÄ± DÃ¶ndÃ¼rme
- TanÄ±mlanan varlÄ±klar ve bunlara iliÅŸkin duygu analizi sonuÃ§larÄ± (pozitif, negatif, nÃ¶tr) kullanÄ±cÄ±ya JSON formatÄ±nda geri dÃ¶ndÃ¼rÃ¼lÃ¼r.

-
-
-
-
-
-
------------ YAPILAN DÄ°ÄER Ä°ÅLEM ADIMLARI DETAYLANDIRILACAK VE FASTAPI ARAYÃœZ Ã‡IKTILARI BURAYA EKLENECEK --------------------


## F) ğŸ”§ Kurulum

1. Projeyi klonlayÄ±n:

    ```bash
    git clone https://github.com/sevimonline/Musteri-Hizmetleri-Cozumleri-Turkce-Platformu-DATA-DESTROYERS](https://github.com/gozdecerenyildiz/Teknofest-NLP-Yarismasi-Seneryo-Kategorisi-DATA-DESTROYERS.git
    ```

2. Proje dizinine gidin:

    ```bash
    cd Teknofest-NLP-Yarismasi-Seneryo-Kategorisi-DATA-DESTROYERS
    ```

3. Gerekli paketleri yÃ¼kleyin:

    ```bash
    pip install -r requirements.txt
    ```

4. UygulamayÄ± baÅŸlatÄ±n:

    ```bash
    uvicorn main:app --reload
    ```

5. TarayÄ±cÄ±nÄ±zda `http://localhost:8000` adresine gidin ve uygulamayÄ± kullanmaya baÅŸlayÄ±n.

## ğŸ‘¥ Ä°letiÅŸim

- LinkedIn: [Berke Sevim](https://www.linkedin.com/in/berke-sevim-1565161a2/)
- LinkedIn: [GÃ¶zde Ceren YÄ±ldÄ±z](https://www.linkedin.com/in/gÃ¶zde-ceren-yÄ±ldÄ±z/)
- LinkedIn: [BÃ¼ÅŸra Sulukan](https://www.linkedin.com/in/bÃ¼ÅŸra-sulukan-82299a177/)

## ğŸ“„ Lisans

Bu proje Apache 2.0 LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.





